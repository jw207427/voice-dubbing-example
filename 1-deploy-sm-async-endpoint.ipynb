{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc1805-013e-4c23-bb58-ed9063a7fd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorchModel  \n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "from sagemaker.utils import name_from_base\n",
    "import sagemaker\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98767013-452a-47a1-bcb2-d0d3f3c0f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r prefix\n",
    "%store -r model_uncompressed_s3\n",
    "%store -r bucket_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8654a7a-9586-4a2b-a656-9299c7af6385",
   "metadata": {},
   "source": [
    "### > setup uncompressed model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d72f492-2ec4-41bc-9d2a-173e23c00926",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data={\n",
    "    'S3DataSource': {\n",
    "        'S3Uri': model_uncompressed_s3,\n",
    "        'S3DataType': 'S3Prefix',\n",
    "        'CompressionType': 'None'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bc4067-b0f2-4e60-98c1-b606ed83d3ce",
   "metadata": {},
   "source": [
    "### > Create a new PyTorch model\n",
    "\n",
    "You can use this model to deploy to realtime or Async endpoint. This model is really slow, realtime endpoint will always error due to inference time out. Therefore we will use Async endpoint instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215318e4-08f1-49db-bbf1-89152403eb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = name_from_base(f\"{prefix}-model\")\n",
    "\n",
    "model = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    framework_version=\"2.1\",\n",
    "    py_version=\"py310\",\n",
    "    role=get_execution_role(),\n",
    "    env={\n",
    "        'SAGEMAKER_TS_RESPONSE_TIMEOUT': '900',\n",
    "        'SM_MODEL_DIR': '/opt/ml/model',\n",
    "        'SAGEMAKER_PROGRAM': 'inference.py'\n",
    "    },\n",
    "    name=model_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591d9a1-88fa-4730-8eda-0daba743999d",
   "metadata": {},
   "source": [
    "endpoint_name = name_from_base(f\"{prefix}-endpoint\")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cf246c-1ddb-4505-9eac-6846cba38b47",
   "metadata": {},
   "source": [
    "### > Create async endpoitn with SageMaker SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7374db7f-99cc-4083-b7ee-611bc4a054df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference import AsyncInferenceConfig\n",
    "\n",
    "# Create an AsyncInferenceConfig object\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=f\"s3://{bucket_name}/{prefix}/output\", \n",
    "    max_concurrent_invocations_per_instance = 2,\n",
    "    # notification_config = {\n",
    "            #   \"SuccessTopic\": \"arn:aws:sns:us-east-2:123456789012:MyTopic\",\n",
    "            #   \"ErrorTopic\": \"arn:aws:sns:us-east-2:123456789012:MyTopic\",\n",
    "    # }, #  Notification configuration \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf0d984-64cc-4f70-9add-54783ccba3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model for async inference\n",
    "endpoint_name = name_from_base(f\"{prefix}-async-endpoint\")\n",
    "\n",
    "async_predictor = model.deploy(\n",
    "    async_inference_config=async_config,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e4af5b-1597-4cbd-96f7-372c54097d88",
   "metadata": {},
   "source": [
    "### > invoke async endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d0263-3e9a-4675-a3fb-dd7496732e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "payload = {\"text\": \"The lead engineer, a confident woman, stands before them, her presentation deck loaded.\", \n",
    "            \"voice_id\": \"female_voice\", #male_voice, female_voice, adam, vladimire, swami\n",
    "            \"output_bucket\": bucket_name,\n",
    "            \"output_key\": f\"{prefix}/output/wav_file/{str(uuid.uuid4())}.wav\",\n",
    "            \"inference_params\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8ebb5-a845-475f-a7d3-84aeb57ec0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = async_predictor.predict_async(\n",
    "    data=payload,\n",
    "    initial_args={'ContentType': 'application/json'})\n",
    "print(response.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cae950-bb97-4919-ad78-68e8c04cd178",
   "metadata": {},
   "source": [
    "### > Invoke in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0ba041-efb7-446b-8286-96775ab10b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "for voice_id in [\"male_voice\", \"female_voice\", \"adam\", \"vladimire\", \"swami\"]:\n",
    "    p = payload.copy()\n",
    "    p[\"voice_id\"] = voice_id\n",
    "    p[\"output_key\"] = f\"{prefix}/output/wav_file/{str(uuid.uuid4())}.wav\"\n",
    "\n",
    "    \n",
    "    response = async_predictor.predict_async(\n",
    "        data=p,\n",
    "        initial_args={'ContentType': 'application/json'}\n",
    "    )\n",
    "    print(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
